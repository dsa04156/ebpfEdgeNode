# eBPF-based Edge Node Selection for Network-Aware Kubernetes Scheduling

## ğŸ“‹ ëª©ì°¨

1. [ì‹¤í—˜ ëª©í‘œ](#ì‹¤í—˜-ëª©í‘œ)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ì„¤ì¹˜ ë° êµ¬ì„±](#ì„¤ì¹˜-ë°-êµ¬ì„±)
4. [ì‹¤í—˜ ì‹¤í–‰](#ì‹¤í—˜-ì‹¤í–‰)
5. [ê²°ê³¼ ë¶„ì„](#ê²°ê³¼-ë¶„ì„)
6. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
7. [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

## ğŸ¯ ì‹¤í—˜ ëª©í‘œ

eBPF ê¸°ë°˜ í…”ë ˆë©”íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•œ "ì—£ì§€ ë…¸ë“œ ì„ íƒ(ë„¤íŠ¸ì›Œí¬ ì¸ì§€ ìŠ¤ì¼€ì¤„ë§)"ì´ ê¸°ë³¸ ìŠ¤ì¼€ì¤„ë§ ëŒ€ë¹„ ë‹¤ìŒ ì§€í‘œë“¤ì„ ê°œì„ í•˜ëŠ”ì§€ ê²€ì¦:

### ì£¼ìš” í‰ê°€ì§€í‘œ
- **ì§€ì—°**: p50/p99 response latency
- **ì‹ ë¢°ì„±**: ì˜¤ë¥˜/ë“œë¡­ë¥ 
- **ì²˜ë¦¬ëŸ‰**: QPS (Queries Per Second)
- **íš¨ìœ¨ì„±**: CPU/ë°±ë§Œ ë©”ì‹œì§€
- **ì•ˆì •ì„±**: ìŠ¤ì¼€ì¤„ ì•ˆì •ì„±(ì¬ìŠ¤ì¼€ì¤„ ë¹ˆë„)
- **ìš´ì˜ì„±**: MTTR(ìŠ¤ì¼€ì¤„ëŸ¬ ë¡¤ë°± ì‹œê°„), ë„ì…/ìš´ì˜ ë‚œì´ë„

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Test Pods     â”‚  â”‚   eBPF Agent    â”‚  â”‚  Scheduler   â”‚ â”‚
â”‚  â”‚   (Workloads)   â”‚  â”‚  (DaemonSet)    â”‚  â”‚  (Plugin)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Prometheus    â”‚  â”‚    Grafana      â”‚  â”‚   Cilium     â”‚ â”‚
â”‚  â”‚  (Monitoring)   â”‚  â”‚  (Dashboard)    â”‚  â”‚    (CNI)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### eBPF í…”ë ˆë©”íŠ¸ë¦¬ ìˆ˜ì§‘

1. **RTT ì¸¡ì •**: `tracepoint:tcp:tcp_ack`ë¡œ `tcp_sock->srtt_us` ìƒ˜í”Œë§
2. **ì¬ì „ì†¡ë¥ **: `tracepoint:tcp:tcp_retransmit_skb` ì¹´ìš´íŠ¸
3. **ë“œë¡­ ì‚¬ìœ **: `tracepoint:skb:kfree_skb`ì—ì„œ reason ë§µ ì¹´ìš´íŠ¸
4. **ìŠ¤ì¼€ì¤„ëŸ¬ ëŒ€ê¸°ì‹œê°„**: `tracepoint:sched:sched_wakeup/sched_switch` ê¸°ë°˜
5. **CPU ì‚¬ìš©ë¥ **: `/proc/stat` ë°ì´í„°ì™€ cgroup ê³„ì¸¡ ê²°í•©

### ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜

```
score_raw = w1Ã—norm(RTT_p99) + w2Ã—norm(retrans_rate) + w3Ã—norm(drop_rate_weighted) 
          + w4Ã—norm(runqlat_p95) + w5Ã—norm(cpu_util)

where:
- ê°€ì¤‘ì¹˜: RTT(0.3), Retrans(0.2), Drop(0.2), Runqlat(0.15), CPU(0.15)
- drop_rate_weighted: ë“œë¡­ reasonë³„ ê°€ì¤‘ì¹˜ ì ìš©
- ëª¨ë“  ë©”íŠ¸ë¦­ì€ [0,1] ë²”ìœ„ë¡œ ì •ê·œí™”
```

## âš™ï¸ ì„¤ì¹˜ ë° êµ¬ì„±

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **OS**: Ubuntu Server 22.04 LTS
- **ì»¤ë„**: â‰¥ 5.15 (ê¶Œì¥: 5.17+)
- **í•˜ë“œì›¨ì–´**: 
  - Control Plane: 4 vCPU / 8GB / 40GB
  - Worker Nodes: 4 vCPU / 8GB / 40GB Ã— 3~7ëŒ€
- **ë„¤íŠ¸ì›Œí¬**: VM ê°„ í†µì‹  ê°€ëŠ¥

### 1ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° êµ¬ì¶•

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
sudo apt-get update
sudo apt-get install -y curl wget git make

# í”„ë¡œì íŠ¸ í´ë¡ 
git clone <this-repository>
cd edgenode

# Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì¶•
cd infrastructure
chmod +x setup-cluster.sh
./setup-cluster.sh
```

### 2ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬

```bash
cd ../monitoring
chmod +x deploy.sh
./deploy.sh
```

### 3ë‹¨ê³„: eBPF ì—ì´ì „íŠ¸ ë°°í¬

```bash
cd ../ebpf-agent
make dev-setup        # ê°œë°œ ë„êµ¬ ì„¤ì¹˜
make check-kernel     # ì»¤ë„ í˜¸í™˜ì„± í™•ì¸
make smoke-test       # bpftraceë¡œ ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸
make deploy          # DaemonSet ë°°í¬
```

### 4ë‹¨ê³„: ì»¤ìŠ¤í…€ ìŠ¤ì¼€ì¤„ëŸ¬ ë°°í¬

```bash
cd ../scheduler
make deps            # Go ì˜ì¡´ì„± ì„¤ì¹˜
make deploy         # ìŠ¤ì¼€ì¤„ëŸ¬ ë°°í¬
```

### 5ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì›Œí¬ë¡œë“œ ë°°í¬

```bash
cd ../workloads
chmod +x deploy.sh
./deploy.sh
```

## ğŸ§ª ì‹¤í—˜ ì‹¤í–‰

### ê¸°ë³¸ ì‹¤í—˜ ì‹¤í–‰

```bash
# ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
make experiment SCENARIO=S1 MODE=proposed RPS=500

# ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
./experiments/run-all-scenarios.sh

# ë² ì´ìŠ¤ë¼ì¸ ì¸¡ì •
make baseline
```

### ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤

| ì‹œë‚˜ë¦¬ì˜¤ | ì„¤ëª… | ì ìš© ë°©ë²• |
|---------|------|----------|
| **S1** | ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì¦ê°€ (20ms Â± 5ms) | `tc qdisc add dev eth0 root netem delay 20ms 5ms` |
| **S2** | íŒ¨í‚· ì†ì‹¤/ì¬ì „ì†¡ (2%) | `tc qdisc add dev eth0 root netem loss 2%` |
| **S3** | ëŒ€ì—­í­ ì œí•œ (50Mbit) | `tc qdisc add dev eth0 root tbf rate 50mbit` |
| **S4** | CPU ì••ë ¥ ì£¼ì… | `stress-ng --cpu 4 --timeout 600s` |
| **S5** | ê°„í—ì  ë„¤íŠ¸ì›Œí¬ ì¥ì•  | 10ì´ˆ ê°„ê²© on/off ìŠ¤í¬ë¦½íŠ¸ |

### ìŠ¤ì¼€ì¤„ë§ ëª¨ë“œ

1. **Baseline**: ê¸°ë³¸ Kubernetes ìŠ¤ì¼€ì¤„ëŸ¬
2. **NetworkAware**: ì°¸ì¡° ë„¤íŠ¸ì›Œí¬ ì¸ì§€ ìŠ¤ì¼€ì¤„ëŸ¬ (ì„ íƒì‚¬í•­)
3. **Proposed**: eBPF ê¸°ë°˜ ì œì•ˆ ë°©ì‹

### ì‹¤í—˜ ë§¤ê°œë³€ìˆ˜

```bash
# ê¸°ë³¸ ì„¤ì •
SCENARIO=S1          # ì‹œë‚˜ë¦¬ì˜¤ (S1-S5)
MODE=proposed        # ìŠ¤ì¼€ì¤„ë§ ëª¨ë“œ
RPS=500             # ìš”ì²­ë¥  (100, 500, 1000)
REPLICAS=5          # ë°˜ë³µ íšŸìˆ˜
DURATION=600        # ì¸¡ì • ì‹œê°„ (ì´ˆ)
WARMUP=300         # ì›Œë°ì—… ì‹œê°„ (ì´ˆ)
COOLDOWN=300       # ì¿¨ë‹¤ìš´ ì‹œê°„ (ì´ˆ)
```

### ê³ ê¸‰ ì‹¤í—˜ ì‹¤í–‰

```bash
# ì‚¬ìš©ì ì •ì˜ ì‹¤í—˜
./experiments/run-experiment.sh S2 proposed 1000 3 900

# ë°°ì¹˜ ì‹¤í—˜ (ëª¨ë“  ì¡°í•©)
./experiments/run-batch-experiments.sh

# íŠ¹ì • ì›Œí¬ë¡œë“œë§Œ í…ŒìŠ¤íŠ¸
./experiments/run-workload-specific.sh inference S1 proposed
```

## ğŸ“Š ê²°ê³¼ ë¶„ì„

### ìˆ˜ì§‘ë˜ëŠ” ë©”íŠ¸ë¦­

#### ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
- **ì§€ì—°ì‹œê°„**: p50, p99 response latency (ms)
- **ì²˜ë¦¬ëŸ‰**: ì‹¤ì œ QPS
- **ì˜¤ë¥˜ìœ¨**: HTTP ì˜¤ë¥˜ ë¹„ìœ¨ (%)
- **ê°€ìš©ì„±**: ì„œë¹„ìŠ¤ ì‘ë‹µë¥ 

#### eBPF í…”ë ˆë©”íŠ¸ë¦¬
- **RTT**: `ebpf_rtt_p50_milliseconds`, `ebpf_rtt_p99_milliseconds`
- **ì¬ì „ì†¡**: `ebpf_tcp_retrans_rate`
- **ë“œë¡­**: `ebpf_drop_rate`, `ebpf_drop_reason_rate{reason}`
- **ìŠ¤ì¼€ì¤„ë§**: `ebpf_runqlat_p95_milliseconds`
- **ë¦¬ì†ŒìŠ¤**: `ebpf_cpu_utilization`

#### ìŠ¤ì¼€ì¤„ëŸ¬ ë©”íŠ¸ë¦­
- **ìŠ¤ì½”ì–´**: `scheduler_framework_score{plugin,node}`
- **ì§€ì—°ì‹œê°„**: `scheduler_e2e_scheduling_latency_seconds`
- **ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ ìŠ¤ì¼€ì¤„ë§ ìˆ˜

### ìë™ ë¶„ì„

ì‹¤í—˜ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ê²°ê³¼:

1. **`experiment_summary.csv`**: ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
2. **`statistical_analysis.csv`**: í†µê³„ì  ìœ ì˜ì„± ë¶„ì„
3. **`experiment_results.png`**: ì‹œê°í™” ì°¨íŠ¸
4. **ê°œë³„ ì‹¤í—˜ ë°ì´í„°**: JSON, CSV í˜•íƒœ

### ìˆ˜ë™ ë¶„ì„

```bash
# Prometheus ì¿¼ë¦¬ ì˜ˆì œ
curl "http://localhost:30090/api/v1/query?query=ebpf_rtt_p99_milliseconds"

# Grafana ëŒ€ì‹œë³´ë“œ ì ‘ì†
# http://localhost:30300 (admin/admin123)

# ê²°ê³¼ ë””ë ‰í„°ë¦¬ í™•ì¸
ls /tmp/experiment-results/$(date +%Y%m%d-*)
```

### ì„±ê³µ íŒì • ê¸°ì¤€

ë‹¤ìŒ ì¡°ê±´ ì¤‘ í•˜ë‚˜ ì´ìƒ ì¶©ì¡± ì‹œ ì„±ê³µ:
- ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ p99 ì§€ì—° **10% ì´ìƒ ê°ì†Œ**
- ì˜¤ë¥˜/ë“œë¡­ë¥  **20% ì´ìƒ ê°ì†Œ**
- ë™ë“± ì²˜ë¦¬ëŸ‰ì—ì„œ CPU/ë°±ë§Œë©”ì‹œì§€ **10% ì´ìƒ ê°œì„ **
- MTTR **â‰¤ 3ë¶„** (ìŠ¤ì¼€ì¤„ëŸ¬ ë¡¤ë°±)
- ìŠ¤ì½”ì–´-ì§€ì—° ìƒê´€ê´€ê³„ **Ï â‰¥ 0.6**

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. eBPF í”„ë¡œê·¸ë¨ ë¡œë“œ ì‹¤íŒ¨

```bash
# BTF ì§€ì› í™•ì¸
ls /sys/kernel/btf/vmlinux

# ê¶Œí•œ í™•ì¸
kubectl logs -n observability -l app=ebpf-edge-agent

# ì»¤ë„ ëª¨ë“ˆ í™•ì¸
lsmod | grep bpf
```

#### 2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì•ˆë¨

```bash
# Prometheus targets í™•ì¸
curl http://localhost:30090/api/v1/targets

# ServiceMonitor í™•ì¸
kubectl get servicemonitor -A

# ì—ì´ì „íŠ¸ ë¡œê·¸ í™•ì¸
kubectl logs -n observability daemonset/ebpf-edge-agent
```

#### 3. ìŠ¤ì¼€ì¤„ëŸ¬ ë™ì‘ ì•ˆí•¨

```bash
# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system -l app=network-aware-scheduler

# ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l app=network-aware-scheduler

# ì„¤ì • í™•ì¸
kubectl get configmap network-aware-scheduler-config -n kube-system -o yaml
```

#### 4. ì‹¤í—˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨

```bash
# ë…¸ë“œ ì ‘ê·¼ì„± í™•ì¸
kubectl get nodes -o wide

# ë„¤íŠ¸ì›Œí¬ ì¡°ê±´ í™•ì¸
ssh node1 "tc qdisc show dev eth0"

# ë¡œë“œ í…ŒìŠ¤íŠ¸ ë„êµ¬ ì„¤ì¹˜ í™•ì¸
which fortio
```

### ë¡œê·¸ ìœ„ì¹˜

```bash
# eBPF ì—ì´ì „íŠ¸ ë¡œê·¸
kubectl logs -n observability daemonset/ebpf-edge-agent -f

# ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸
kubectl logs -n kube-system -l app=network-aware-scheduler -f

# ì‹¤í—˜ ë¡œê·¸
tail -f /tmp/experiment-results/latest/experiment.log

# ì‹œìŠ¤í…œ ë¡œê·¸
journalctl -u kubelet -f
```

### ë¡¤ë°± ì ˆì°¨ (MTTR ì¸¡ì •)

```bash
# ë¹ ë¥¸ ë¡¤ë°± (ìë™ ì‹œê°„ ì¸¡ì •)
cd scheduler
make rollback

# ìˆ˜ë™ ë¡¤ë°±
kubectl patch deployment kube-scheduler -n kube-system \
  -p '{"spec":{"template":{"spec":{"containers":[{"name":"kube-scheduler","image":"k8s.gcr.io/kube-scheduler:v1.28.4"}]}}}}'

# ì™„ì „ ì •ë¦¬
cd scripts
./cleanup.sh --all
```

## ğŸ§¹ ì •ë¦¬

### ë¶€ë¶„ ì •ë¦¬

```bash
# íŠ¹ì • ì»´í¬ë„ŒíŠ¸ë§Œ ì •ë¦¬
./scripts/cleanup.sh --workloads    # ì›Œí¬ë¡œë“œë§Œ
./scripts/cleanup.sh --monitoring   # ëª¨ë‹ˆí„°ë§ë§Œ
./scripts/cleanup.sh --ebpf         # eBPF ì—ì´ì „íŠ¸ë§Œ
./scripts/cleanup.sh --scheduler    # ìŠ¤ì¼€ì¤„ëŸ¬ë§Œ
./scripts/cleanup.sh --network      # ë„¤íŠ¸ì›Œí¬ ì¡°ê±´ë§Œ
```

### ì „ì²´ ì •ë¦¬

```bash
# ëª¨ë“  ì‹¤í—˜ ì»´í¬ë„ŒíŠ¸ ì •ë¦¬
./scripts/cleanup.sh --all

# ìƒíƒœ í™•ì¸
./scripts/cleanup.sh --status

# ì™„ì „ ì´ˆê¸°í™” (ìœ„í—˜)
./scripts/cleanup.sh --destructive
```

## ğŸ“š ì°¸ê³  ìë£Œ

### ê¸°ìˆ  ë¬¸ì„œ

- [eBPF Documentation](https://ebpf.io/what-is-ebpf/)
- [Kubernetes Scheduler Framework](https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/)
- [Cilium eBPF Guide](https://docs.cilium.io/en/latest/bpf/)
- [Prometheus Monitoring](https://prometheus.io/docs/)

### ê´€ë ¨ ë…¼ë¬¸

- "eBPF for Network Function Virtualization" (NSDI 2021)
- "Network-Aware Scheduling in Kubernetes" (SIGCOMM 2020)
- "Performance Isolation in Multi-tenant Edge Computing" (EuroSys 2022)

### ì¶”ê°€ ë„êµ¬

- [bpftrace](https://github.com/iovisor/bpftrace) - eBPF ìŠ¤í¬ë¦½íŒ…
- [BCC](https://github.com/iovisor/bcc) - eBPF ë„êµ¬ ëª¨ìŒ
- [Fortio](https://github.com/fortio/fortio) - ë¡œë“œ í…ŒìŠ¤íŒ…
- [Grafana](https://grafana.com/docs/) - ì‹œê°í™”

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:

1. GitHub Issuesì— ë¬¸ì œ ë³´ê³ 
2. ë¬¸ì„œ í™•ì¸: `/docs` ë””ë ‰í„°ë¦¬
3. ë¡œê·¸ ë¶„ì„: ìœ„ì˜ ë¬¸ì œ í•´ê²° ì„¹ì…˜ ì°¸ì¡°
4. ì»¤ë®¤ë‹ˆí‹° ì§€ì›: [eBPF Slack](https://ebpf.io/slack)
